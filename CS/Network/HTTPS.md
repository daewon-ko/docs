**Gateway 패턴 및 통신 구간 별 프로토콜 정리**



- GateWay란?(정의)
- 기능과 역할
- 백엔드 서버에서 어떻게 사용되는가?
- 구간 별 통신 프로토콜을 어떻게 하는가?
  - HTTP Or HTTPS OR GRPC OR etc

**HTTP란?**

- 웹 상에서 데이터를 주고 받기 위한 Application Layer 프로토콜
- 클라이언트와 서버간의 요청 /응답 형태로 통신이 이뤄진다.



**HTTP와 REST는 어떻게 무엇이 다를까?** 

HTTP는 프로토콜 , REST는 사용자 규약이다. 



REST는 HTTP를 조금 더 잘 사용하기 위함





[API 개념정복 | REST API | gRPC](https://www.youtube.com/watch?v=HmvNuI0Ku9I)

- REST의 6가지 특징

**HTTPS란**

- Application Layer와 TCP Layer 사이에 보안계층(SSL/ TLS)를 중간에 Layer로써 둠으로써 Http에 보안을 적용한 형태
- 클라이언트와 서버 간 데이터가 암호화되어 전송되므로 도청이나 공격에 강하다.



CF) SSL / TLS 계층 및 SSL 인증서

- SSL /TLS 계층은 클라이언트와 서버 사이의 암호화를 설정하고 무결성과 인증을 보장
- SSL 인증서
  - 서버가 자신이 신뢰할 수 있는 주체임을 증명하기 위해 필요
  - CA(Certificate Authority)로부터 발행된 인증서를 서버가 갖고있어야 한다.
  - 클라이언트(브라우저)는 서버가 제시하는 인증서를 검증해 통신 상대가 신뢰할 수 있는지 판단
- 핸드쉐이크 과정
  - ​	▪	TLS 인증서 발급
    - 
    - 기업이나 개인이 CA에서 인증서 발급을 신청하여 인증서 발행
    - 서버 (게이트웨이 구성)
      - 발급받은 인증서(서버 인증서)와 개인 키(Private key)를 Nginx와 같은 게이트웨이 서버에 배포
    - 클라이언트 검증
      - 클라이언트(브라우저 등)이 게이트웨이 접속 시에, 게이트웨이는 서버 인증서를 제시
      - 클라이언트는 운영 체제나 브라우저 등에 내장된 신뢰 가능한 루트CA 목록을 통해 인증서의 서명과 유효기간, 도메인 일치여부 등 검사
      - 검증이 성공하면 TLS 핸드쉐이크 과정을 통해 암호화 채널이 형성됨



클라이언트-서버 간 TLS 핸드셰이크의 암호화 알고리즘/키 교환, 인증서 검증 과정
 TLS 핸드셰이크는 클라이언트와 서버가 안전한 통신 경로를 확립하기 위해 수행하는 절차다. 전체 과정을 순서대로 살펴보면 다음과 같다:

​	1	ClientHello

​	◦	클라이언트는 자신이 지원하는 TLS 프로토콜 버전(예: TLS 1.2, 1.3), 암호화 스위트(예: RSA, ECDHE, AES-GCM 등), 압축 방식 등을 서버에 제안한다.

​	◦	클라이언트가 세션 재개(세션 ID 또는 세션 티켓)를 지원하는 경우 해당 정보를 함께 보낸다.

​	2	ServerHello

​	◦	서버는 클라이언트가 제안한 옵션 중에서 프로토콜 버전, 암호화 스위트 등을 결정해 응답한다.

​	◦	선택된 암호화 알고리즘(예: ECDHE-RSA-AES256-GCM-SHA384 등)에 따라 이후 통신이 진행된다.

​	3	서버 인증서 송신

​	◦	서버는 자신의 신원 증명을 위해 CA(인증기관)로부터 발급받은 SSL/TLS 인증서를 클라이언트로 보낸다.

​	◦	클라이언트는 서버의 인증서를 받아서 신뢰할 수 있는 CA 목록과 CRL(인증서 폐기 목록) 등을 참조해 유효성을 검사한다(만료, 발급자, 도메인 일치 여부 등).

​	◦	HTTPS 브라우저 환경에서 사용자는 보통 이 과정을 자동으로 처리한다.

​	4	키 교환(예: ECDHE 방식)

​	◦	(TLS 1.2 기준) Diffie-Hellman(DH) 또는 ECDH(Elliptic Curve Diffie-Hellman) 방식을 활용해 클라이언트와 서버가 대칭키(session key)를 안전하게 교환한다.

​	◦	서버가 ECDHE 파라미터(공개키)를 전송하면, 클라이언트는 이를 이용해 자신의 비밀키와 연산하여 프리마스터 시크릿(pre-master secret)을 생성한다. 이를 기반으로 최종 세션 키(master secret)를 만들어낸다.

​	5	ServerHelloDone & ClientKeyExchange

​	◦	서버는 모든 정보를 전달한 후 ServerHelloDone 메시지를 통해 “나는 다 보냈으니, 네가 받은 정보로 처리해라”라고 알린다.

​	◦	클라이언트는 이에 대해 ClientKeyExchange 메시지를 보낼 수도 있는데, ECDHE 모드라면 클라이언트의 공개키 혹은 DH 파라미터를 전송한다.

​	6	ChangeCipherSpec & Finished

​	◦	클라이언트와 서버 모두 ChangeCipherSpec 메시지를 교환해 “이제부터 데이터는 협상된 키와 알고리즘으로 암호화하겠다”고 선언한다.

​	◦	Finished 메시지를 통해 자신의 메시지 무결성을 확인하고 “핸드셰이크가 정상적으로 완료됨”을 알린다.

​	7	데이터 통신

​	◦	핸드셰이크가 끝나면 협상된 대칭키로 애플리케이션 데이터를 암호화해 전송한다.

이 과정을 통해 양쪽은 신뢰할 수 있는 암호화 채널을 형성하며, 인증서는 서버의 정당성을 검증한다. (TLS 1.3에서 절차는 일부 간소화되지만, 근본적 개념은 유사하다.)







**HTTP와 HTTPS의 차이**

- 암호화 여부
  - HTTP는 평문 통신 / HTTPS는 암호화채널(TLS/ SSL)을 통해 통신
- HTTPS는 80 / HTTPS는 443포트를 기본적으로 이용
- HTTPS는 인증서를 사용해 서버의 신뢰성과 소유자 증명
- 리소스 사용
  - HTTPS는 암호화/복호화 과정에서 서버의 CPU등 리소스를 소모할 수 있음



**GateWay란?**

- 외부 네트워크와 내부 네트워크 간 또는 여러 서비스들 간에서 트래픽을 중계, 제어하는 역할을 하는 구성요소이다.
- 일반적으로 프록시 역할을 수행하고 로드밸런싱, 리버스프록시 등 다양한 기능을 제공한다.



그렇다면 클라이언트와 Gateway, Gateway와 WAS간 통신 프로토콜은 무엇을 둘 수 있을까?

먼저 클라이언트와 GateWay부터 공부해보자. 



**클라이언트 - Gateway** 



- 일반적인 클라이언트와 Gateway서버 사이에는 HTTPS를 적용한다.
- 클라이언트가 접속하는 구간이 인터넷에 노출되므로 암호화(HTTPS 적용)을 통해 보안을 강화할 수 있다.



그렇다면 Gateway와 WAS는 어떤 프로토콜을 이용해야할까? 

**Gateway - WAS**



Gateway와 WAS 사이 통신 프로토콜은 크게봐서 HTTP와 HTTPS의 선택지가 있다. 



- HTTP 선택
  - 장점
    - 암호화 부담이 없고 CPU 오버헤드가 적다.
  - 단점
    - 게이트웨이 내부망이 노출될경우 중요데이터(회원정보 , 결제 내역등)의 데이터를 평문으로 송수신하게 되어 유출될 수 있다.
- HTTPS 선택
  - 장점
    - 게이트웨이와 WAS간에 암호화를 적용하여 보안성 극대화 가능하다.
    - 특히 MSA 적용시, 마이크로서비스간 통신을 보안하는데 유리하다.
  - 단점
    - 추가적인 인증서 관리가 필요하다(각 인증서와 키를 WAS마다 배포하고 관리해아함)
    - 암호화 /복호화 오버헤드가 쌓이면서 CPU 사용률이 증가할 수 있음





*CF)gRPC (HTTP/2 기반)*



- 구글이 만든 오픈소스로, 프로토콜 버퍼(Protocol Buffers)를 이용한 바이너리 직렬화를 한다. HTTP/2를 기반으로 하기 때문에 다중화, 헤더 압축 등을 활용해 성능 최적화가 가능하다.
- 마이크로서비스 간 low-latency, high-throughput 통신에 효과적이다. 양방향 스트리밍도 가능하다.
- TLS 적용도 용이하며, 세부적인 설정으로 보안과 성능을 균형있게 잡을 수 있다.





🔹 gRPC가 HTTPS보다 성능이 좋은 이유

✅ 1) HTTP/2 다중 요청 처리 (Multiplexing)

​	•	HTTP/1.1 기반 HTTPS는 한 번에 하나의 요청만 처리할 수 있어, 많은 요청을 보낼 경우 연결이 병목이 될 수 있다.

​	•	gRPC는 HTTP/2 기반으로 하나의 TCP 연결에서 다중 요청을 동시에 처리할 수 있다.

​	•	즉, 여러 개의 API 요청을 하나의 연결에서 처리할 수 있어 TLS 핸드셰이크 비용을 줄인다.

✅ 2) TLS 핸드셰이크 감소

​	•	HTTP/1.1에서는 요청마다 새로운 연결을 생성하는 경우가 많지만,

​	•	HTTP/2(gRPC)는 하나의 지속적인 TLS 연결을 유지하며 다중 요청을 처리할 수 있다.

​	•	즉, 반복적인 TLS 핸드셰이크 비용을 줄이고, 연결 유지 비용을 절감할 수 있다.

✅ 3) 헤더 크기 최적화 (HPACK 압축)

​	•	일반적인 HTTPS REST API에서는 요청마다 전체 헤더를 포함해야 한다.

​	•	반면, gRPC는 HPACK 헤더 압축을 사용하여 필요한 데이터만 압축해서 전송한다.

​	•	결과적으로 네트워크 오버헤드를 줄이고 HTTPS 성능 저하를 방지할 수 있다.

✅ 4) 바이너리 직렬화 (Protocol Buffers 사용)

​	•	REST API는 JSON(텍스트 기반)을 사용하기 때문에 데이터 크기가 크고,

​	•	gRPC는 바이너리 포맷(Protocol Buffers, Protobuf)을 사용하여 데이터 크기를 최소화한다.

​	•	데이터 크기가 작아지므로, TLS 암호화 대상이 줄어들어 성능 저하를 방지할 수 있다.

✅ 5) 서버 스트리밍 및 양방향 스트리밍 지원

​	•	gRPC는 서버 스트리밍(Server Streaming)과 양방향 스트리밍(Bidirectional Streaming)을 지원하여,

​	•	일반적인 HTTPS보다 데이터를 더욱 효율적으로 전송할 수 있다.

​	•	예를 들어, 클라이언트가 대량의 데이터를 요청할 때 gRPC 스트리밍을 활용하면 한 번의 요청으로 지속적으로 데이터를 받을 수 있어 성능 최적화가 가능하다.













**SSL Termination**

- 클라이언트와 서버 간의 HTTPS 통신을 위해 SSL / TLS 암호화를 수행하는데, Nginx에서 수행 및 처리하고 내부 서버(WAS)와의 통신에서는 HTTP로만 통신하는 방식
- 즉, Nginx가 **HTTPS요청을 받아** 복호화한 이후에 해당 요청을 WAS로는 **HTTP로 전달**
- 장점
  - WAS의 부하 감소
    - WAS에서 직접 SSL/TLS 처리를 안하고 Nginx에서만 한 번 수행
    - WAS의 CPU및 메모리 부담 저하
    - 다수 WAS
  - 성능 최적화 및 요청 속도 향상
    - SSL/TLS에 관한 암호화/ 복호화 과정이 Nginx에서 한 번만 수행
    - 내부 트래픽에서는 암호화 관련한 오버헤드가 없음
    - 내부 네트워크에서 HTTP를 사용하여 속도가 빠름
  - SSL/TLS 인증서 중앙 관리
    - 인증서 갱신/ 교체가 간편
  - 로드 밸런싱 및 프록시 기능과 통합 가능
    - Nginx에서 SSL Termination과 함께 로드밸런싱, 캐싱, 압축 등 다양한 기능 추가 가능
- 단점
  - 내부 통신 보안 취약 가능
  - SPOF(단일 장애 지점)
    - Nginx에서 중앙화하여 보안을 처리하므로 단일장애지점이 된다.
    - Nginx에 장애시 모든 HTTPS 트래픽이 차단 가능
    - HAProxy를 조합하여 이중화 구성 할 수도 있음







**SSL 인증 방식**

[웹사이트 보안을 위한 방법, SSL이란? (feat. SSL과 HTTPS의 차이)](https://blog.naver.com/skinfosec2000/222135874222)

[SSL 인증서란 무엇인가요? - SSL/TLS 인증서 설명 - AWS](https://aws.amazon.com/ko/what-is/ssl-certificate/)

 